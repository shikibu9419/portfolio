@inproceedings{10.1145/3588029.3599735,
author = {Ozawa, Chinatsu and Yamamoto, Kenta and Izumi, Kazuya and Ochiai, Yoichi},
title = {Give Life Back to Alternative Process: Exploring Handmade Photographic Printing Experiments towards Digital Nature Ecosystem},
year = {2023},
isbn = {9798400701535},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3588029.3599735},
doi = {10.1145/3588029.3599735},
abstract = {The proliferation of smartphones has made it easy for anyone to take digital photographs, and the recent popularization of text-to-image models has made it easy for anyone to create images. In this age, by combining digital technology with the tactile experience of handmade processes, we can rediscover the joy of creating with our own hands and the emotional connection that comes from physically interacting with our work. Previously, we proposed a new printing framework that integrated computer processing with full-color cyanotype printing. In this work, we demonstrate expanding the range of aesthetic expressions with computer processing for tone adjustment with several alternative processes such as salt print, platinum print, and cyanotype. In the installation, we present our printing framework with the user interface and exhibit works utilizing our proposed method. The use of new media developed after the digital age and the integration of computer processing in photo printing may be a way to create a new photographic life with the joy of materialising scenery.},
booktitle = {ACM SIGGRAPH 2023 Labs},
articleno = {6},
numpages = {2},
keywords = {Alternative Photographic Process, Simulation, Handmade Photography, Optimization},
location = {Los Angeles, CA, USA},
series = {SIGGRAPH '23}
}

@inproceedings{10.1145/3588028.3603648,
author = {Suzuki, Shieru and Aoyama, Kazuma and Kojima, Ryosei and Izumi, Kazuya and Fushimi, Tatsuki and Ochiai, Yoichi},
title = {ExudedVestibule: Enhancing Mid-Air Haptics through Galvanic Vestibular Stimulation},
year = {2023},
isbn = {9798400701528},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3588028.3603648},
doi = {10.1145/3588028.3603648},
abstract = {This study presents a novel system that enhances air cannon tactile perception using synchronous galvanic vestibular stimulation (GVS). We conducted a user study with a within-subjects design to evaluate the enhancement effects of synchronous GVS on air cannon tactile sensations across multiple body locations. Results demonstrated significant improvements without affecting the magnitude of physical body sway, suggesting potential applications in virtual reality, particularly for augmenting existing air vortex ring haptics use cases.},
booktitle = {ACM SIGGRAPH 2023 Posters},
articleno = {41},
numpages = {2},
keywords = {galvanic vestibular stimulation, mid-air haptics, force illusion},
location = {Los Angeles, CA, USA},
series = {SIGGRAPH '23}
}

@inproceedings{10.1007/978-3-031-35596-7_31,
author = {Izumi, Kazuya and Suzuki, Shieru and Niwa, Ryogo and Shinoda, Atsushi and Iijima, Ryo and Hyakuta, Ryosuke and Ochiai, Yoichi},
title = {A Preliminary Study On&nbsp;Eye Contact Framework Toward Improving Gaze Awareness In&nbsp;Video Conferences},
year = {2023},
isbn = {978-3-031-35595-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-35596-7_31},
doi = {10.1007/978-3-031-35596-7_31},
abstract = {Gaze information plays an important role as non-verbal information in face-to-face conversations. However, in online videoconferences, users’ gaze is perceived as misaligned due to the different positions of the screen and the camera. This problem causes a lack of gaze information, such as gaze awareness. To solve this problem, gaze correction methods in videoconference have been extensively discussed, and these methods allow us to maintain eye contact with other participants even in videoconference. However, people rarely make constant eye contact with the other person in face-to-face conversations. Although a person’s gaze generally reflects their intentions, if the system unconditionally corrects gaze, the intention of the user’s gaze is incorrectly conveyed. Therefore, we conducted a preliminary study to develop an eye contact framework; a system that corrects the user’s gaze only when the system detects that the user is looking at the face of the videoconferencing participant. In this study, participants used this system in a online conference and evaluated it qualitatively. As a result, this prototype was not significant in the evaluation of gaze awareness, but useful feedback was obtained from the questionnaire. We will improve this prototype and aim to develop a framework to facilitate non-verbal communication in online videoconferences.},
booktitle = {Human-Computer Interaction: Thematic Area, HCI 2023, Held as Part of the 25th HCI International Conference, HCII 2023, Copenhagen, Denmark, July 23–28, 2023, Proceedings, Part I},
pages = {484–498},
numpages = {15},
keywords = {Eye Contact, Gaze Awareness, Video Conferencing, Video-mediated Communication, Gaze Interaction, Gesture and Eye-gaze Based Interaction},
location = {Copenhagen, Denmark}
}

@inproceedings{10.1145/3550340.3564219,
author = {Ozawa, Chinatsu and Yamamoto, Kenta and Izumi, Kazuya and Ochiai, Yoichi},
title = {Computational Alternative Photographic Process toward Sustainable Printing},
year = {2022},
isbn = {9781450394659},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550340.3564219},
doi = {10.1145/3550340.3564219},
abstract = {We propose a computational alternative photographic process that integrates computer processing with the conventional printing method, particularly cyanotype. Cyanotype is a non-silver-halide process that has a lower environmental impact and is known for its availability to produce tri-color prints; however, the tri-color process is complex and time-consuming. To simplify this heavy printing process, our framework provides a user interface for image editing and optimization based on color simulation within a printable color gamut. We demonstrate image editing and tri-color cyanotype printing using our framework, indicating that it can reduce the number of user trials and errors.},
booktitle = {SIGGRAPH Asia 2022 Technical Communications},
articleno = {19},
numpages = {4},
keywords = {Data-driven Simulation, Optimization, Alternative Photographic Process, Cyanotype},
location = {Daegu, Republic of Korea},
series = {SA '22}
}

@inproceedings{10.1007/978-3-031-05028-2_31,
author = {Niwa, Ryogo and Izumi, Kazuya and Suzuki, Shieru and Ochiai, Yoichi},
title = {EMS-Supported Throwing: Preliminary Investigation on&nbsp;EMS-Supported Training of&nbsp;Movement Form},
year = {2022},
isbn = {978-3-031-05027-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-05028-2_31},
doi = {10.1007/978-3-031-05028-2_31},
abstract = {We propose a learning support system with extremely low latency and low cognitive load to correct the user’s motion. In previous studies, visual and haptic feedback has been mainly used to support motion learning, but there is a delay between the presentation of the stimulus and the modification of the action. However, this delay is due to reaction time and cognitive load and is difficult to shorten. This study proposed a system for solving this problem by combining Electrical Muscle Stimulation (EMS) and prediction of the user’s motion. In order to improve the control ability of the underhand throwing, we used the system to tell the subject the release point during the underhand throwing motion and verified the learning effect. This experiment revealed that EMS tended to be effective in teaching the ball’s release point, although it did not improve the control ability of the underhand throwing motion. In addition, although the effectiveness of EMS for motion learning was not yet fully evaluated, this study showed the possibility of applying EMS to support learning of motion.},
booktitle = {Universal Access in Human-Computer Interaction. Novel Design Approaches and Technologies: 16th International Conference, UAHCI 2022, Held as Part of the 24th HCI International Conference, HCII 2022, Virtual Event, June 26 – July 1, 2022, Proceedings, Part I},
pages = {459–476},
numpages = {18},
keywords = {Skill learning, Motor skills, Electric stimulation, EMS}
}
